import streamlit as st
import pandas as pd
from dotenv import load_dotenv
import openai
import os
import json
import requests

# .env.local ã‹ã‚‰APIã‚­ãƒ¼ãªã©ã‚’èª­ã¿è¾¼ã‚€
load_dotenv(dotenv_path=".env.local")
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- é–¢æ•°å®šç¾©ã‚¹ã‚­ãƒ¼ãƒ ---
function_definitions = [
    {
        "name": "analyze_data",
        "description": "å›ºå®šã•ã‚ŒãŸe-Stat APIã‹ã‚‰å–å¾—ã—ãŸçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹",
        "parameters": {
            "type": "object",
            "properties": {
                "prompt": {"type": "string"}
            },
            "required": ["prompt"]
        }
    }
]

# --- LLMã«é–¢æ•°å‘¼ã³å‡ºã—ã‚’ä¾é ¼ã™ã‚‹ ---
def call_llm_openai(prompt):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã‹ã‚‰é–¢æ•°ã‚’é¸ã³ã€å¼•æ•°ã‚’æ±ºå®šã—ã¦ãã ã•ã„"},
            {"role": "user", "content": f"prompt={prompt}"}
        ],
        functions=function_definitions,
        function_call="auto"
    )
    fc = response.choices[0].message.function_call
    return {
        "function": fc.name,
        "arguments": json.loads(fc.arguments)
    }

# --- å®Ÿè¡Œã•ã‚Œã‚‹ãƒ­ãƒ¼ã‚«ãƒ«é–¢æ•° ---
def analyze_data(prompt):
    try:
        fixed_api_url = "http://api.e-stat.go.jp/rest/3.0/app/json/getStatsData?appId=honbinliu3@gmail.com&lang=J&statsDataId=0000010106&metaGetFlg=Y&cntGetFlg=N&explanationGetFlg=Y&annotationGetFlg=Y&sectionHeaderFlg=1&replaceSpChars=0"
        res = requests.get(fixed_api_url)
        res.raise_for_status()
        json_data = res.json()

        values = json_data.get("GET_STATS_DATA", {}).get("STATISTICAL_DATA", {}).get("DATA_INF", {}).get("VALUE", [])

        # ãƒ‡ãƒ¼ã‚¿æ•´å½¢
        records = []
        for v in values:
            value = v.get("$")
            try:
                value = float(value) if value is not None else None
            except ValueError:
                value = None
            records.append({
                "area": v.get("@area"),
                "time": v.get("@time"),
                "value": value
            })

        df = pd.DataFrame(records)

        if df.empty or df.shape[1] == 0:
            raise ValueError("å–å¾—ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒç©ºã€ã¾ãŸã¯åˆ—ãŒã‚ã‚Šã¾ã›ã‚“")

        # ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ˜ç¤ºçš„ã«å¤‰æ›ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ï¼‰
        df["value"] = pd.to_numeric(df["value"], errors="coerce")

        summary = df.describe(include='all').to_dict()
        return {"summary": summary, "note": prompt}

    except Exception as e:
        return {
            "summary": {"error": f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã¾ãŸã¯å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"},
            "note": prompt
        }

func_table = {
    "analyze_data": analyze_data,
}

# --- Streamlit UI ---
st.set_page_config(page_title="APIãƒ‡ãƒ¼ã‚¿åˆ†æã‚¢ãƒ—ãƒª", layout="wide")
st.title("ğŸŒ e-Stat APIã«ã‚ˆã‚‹AIãƒ‡ãƒ¼ã‚¿åˆ†æã‚¢ãƒ—ãƒª")

prompt = st.text_input("âœï¸ åˆ†æå†…å®¹ã®æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä¾‹: éƒ½é“åºœçœŒåˆ¥ã«äººå£ã®æœ€å¤§å€¤ã‚’å‡ºã—ã¦")

if st.button("å®Ÿè¡Œ"):
    with st.spinner("LLMãŒåˆ†ææ–¹æ³•ã‚’æ€æ¡ˆä¸­..."):
        try:
            call = call_llm_openai(prompt)
            func = call.get("function")
            args = call.get("arguments", {})

            if func not in func_table:
                st.error(f"âš ï¸ æœªå®šç¾©ã®é–¢æ•°: {func}")
            else:
                result = func_table[func](**args)
                st.subheader("âœ… åˆ†æçµæœ")
                if isinstance(result["summary"], dict):
                    st.json(result["summary"])
                else:
                    st.write(result["summary"])
                st.write("ğŸ’¡ ãƒãƒ¼ãƒˆ:", result["note"])

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
else:
    st.info("åˆ†ææŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ã€å®Ÿè¡Œãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚e-Stat APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚")